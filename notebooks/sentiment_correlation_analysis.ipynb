{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Financial News Sentiment Analysis\n",
    "\n",
    "This notebook analyzes the correlation between financial news sentiment and stock price movements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add src directory to path\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "from src.sentiment_analysis import NewsSentimentAnalyzer\n",
    "from src.stock_data_loader import load_stock_data\n",
    "\n",
    "# Set plot style\n",
    "plt.style.use('default')\n",
    "sns.set_palette('husl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "First, we'll load both the news data and stock data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "News data shape: (1407328, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>headline</th>\n",
       "      <th>url</th>\n",
       "      <th>publisher</th>\n",
       "      <th>date</th>\n",
       "      <th>stock</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Stocks That Hit 52-Week Highs On Friday</td>\n",
       "      <td>https://www.benzinga.com/news/20/06/16190091/s...</td>\n",
       "      <td>Benzinga Insights</td>\n",
       "      <td>2020-06-05 10:30:54-04:00</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Stocks That Hit 52-Week Highs On Wednesday</td>\n",
       "      <td>https://www.benzinga.com/news/20/06/16170189/s...</td>\n",
       "      <td>Benzinga Insights</td>\n",
       "      <td>2020-06-03 10:45:20-04:00</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>71 Biggest Movers From Friday</td>\n",
       "      <td>https://www.benzinga.com/news/20/05/16103463/7...</td>\n",
       "      <td>Lisa Levin</td>\n",
       "      <td>2020-05-26 04:30:07-04:00</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>46 Stocks Moving In Friday's Mid-Day Session</td>\n",
       "      <td>https://www.benzinga.com/news/20/05/16095921/4...</td>\n",
       "      <td>Lisa Levin</td>\n",
       "      <td>2020-05-22 12:45:06-04:00</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>B of A Securities Maintains Neutral on Agilent...</td>\n",
       "      <td>https://www.benzinga.com/news/20/05/16095304/b...</td>\n",
       "      <td>Vick Meyer</td>\n",
       "      <td>2020-05-22 11:38:59-04:00</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                           headline  \\\n",
       "0           0            Stocks That Hit 52-Week Highs On Friday   \n",
       "1           1         Stocks That Hit 52-Week Highs On Wednesday   \n",
       "2           2                      71 Biggest Movers From Friday   \n",
       "3           3       46 Stocks Moving In Friday's Mid-Day Session   \n",
       "4           4  B of A Securities Maintains Neutral on Agilent...   \n",
       "\n",
       "                                                 url          publisher  \\\n",
       "0  https://www.benzinga.com/news/20/06/16190091/s...  Benzinga Insights   \n",
       "1  https://www.benzinga.com/news/20/06/16170189/s...  Benzinga Insights   \n",
       "2  https://www.benzinga.com/news/20/05/16103463/7...         Lisa Levin   \n",
       "3  https://www.benzinga.com/news/20/05/16095921/4...         Lisa Levin   \n",
       "4  https://www.benzinga.com/news/20/05/16095304/b...         Vick Meyer   \n",
       "\n",
       "                        date stock  \n",
       "0  2020-06-05 10:30:54-04:00     A  \n",
       "1  2020-06-03 10:45:20-04:00     A  \n",
       "2  2020-05-26 04:30:07-04:00     A  \n",
       "3  2020-05-22 12:45:06-04:00     A  \n",
       "4  2020-05-22 11:38:59-04:00     A  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load news data\n",
    "news_data = pd.read_csv('../data/raw_analyst_ratings.csv')\n",
    "print(f\"News data shape: {news_data.shape}\")\n",
    "news_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAPL data range: 0 to 10997\n",
      "AMZN data range: 0 to 6845\n",
      "GOOG data range: 0 to 5019\n",
      "META data range: 0 to 2925\n",
      "MSFT data range: 0 to 9671\n",
      "NVDA data range: 0 to 6420\n",
      "TSLA data range: 0 to 3544\n"
     ]
    }
   ],
   "source": [
    "# Load stock data for all symbols\n",
    "symbols = ['AAPL', 'AMZN', 'GOOG', 'META', 'MSFT', 'NVDA', 'TSLA']\n",
    "stock_data = load_stock_data(symbols, data_dir='../data')\n",
    "\n",
    "for symbol in symbols:\n",
    "    if symbol in stock_data:\n",
    "        print(f\"{symbol} data range: {stock_data[symbol].index.min()} to {stock_data[symbol].index.max()}\")\n",
    "    else:\n",
    "        print(f\"No data found for {symbol}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Sentiment Analyzer and Calculate Sentiment Scores\n",
    "\n",
    "We'll create an instance of NewsSentimentAnalyzer and calculate sentiment scores for all headlines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "time data \"2020-05-22 00:00:00\" doesn't match format \"%Y-%m-%d %H:%M:%S%z\", at position 10. You might want to try:\n    - passing `format` if your strings have a consistent format;\n    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Initialize analyzer\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m analyzer = \u001b[43mNewsSentimentAnalyzer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnews_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstock_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Calculate sentiment scores\u001b[39;00m\n\u001b[32m      5\u001b[39m news_with_sentiment = analyzer.calculate_sentiment()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\aweso\\financial-news-sentiment-analysis\\src\\sentiment_analysis.py:31\u001b[39m, in \u001b[36mNewsSentimentAnalyzer.__init__\u001b[39m\u001b[34m(self, news_df, stock_data)\u001b[39m\n\u001b[32m     28\u001b[39m \u001b[38;5;28mself\u001b[39m.sentiment_analyzer = SentimentIntensityAnalyzer()\n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m# Convert date columns to datetime\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m \u001b[38;5;28mself\u001b[39m.news_df[\u001b[33m'\u001b[39m\u001b[33mdate\u001b[39m\u001b[33m'\u001b[39m] = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_datetime\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnews_df\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdate\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m symbol \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stock_data:\n\u001b[32m     33\u001b[39m     \u001b[38;5;28mself\u001b[39m.stock_data[symbol][\u001b[33m'\u001b[39m\u001b[33mDate\u001b[39m\u001b[33m'\u001b[39m] = pd.to_datetime(\u001b[38;5;28mself\u001b[39m.stock_data[symbol][\u001b[33m'\u001b[39m\u001b[33mDate\u001b[39m\u001b[33m'\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\aweso\\financial-news-sentiment-analysis\\.venv\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1063\u001b[39m, in \u001b[36mto_datetime\u001b[39m\u001b[34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[39m\n\u001b[32m   1061\u001b[39m             result = arg.tz_localize(\u001b[33m\"\u001b[39m\u001b[33mutc\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1062\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, ABCSeries):\n\u001b[32m-> \u001b[39m\u001b[32m1063\u001b[39m     cache_array = \u001b[43m_maybe_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_listlike\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1064\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m cache_array.empty:\n\u001b[32m   1065\u001b[39m         result = arg.map(cache_array)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\aweso\\financial-news-sentiment-analysis\\.venv\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py:247\u001b[39m, in \u001b[36m_maybe_cache\u001b[39m\u001b[34m(arg, format, cache, convert_listlike)\u001b[39m\n\u001b[32m    245\u001b[39m unique_dates = unique(arg)\n\u001b[32m    246\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(unique_dates) < \u001b[38;5;28mlen\u001b[39m(arg):\n\u001b[32m--> \u001b[39m\u001b[32m247\u001b[39m     cache_dates = \u001b[43mconvert_listlike\u001b[49m\u001b[43m(\u001b[49m\u001b[43munique_dates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    248\u001b[39m     \u001b[38;5;66;03m# GH#45319\u001b[39;00m\n\u001b[32m    249\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\aweso\\financial-news-sentiment-analysis\\.venv\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py:433\u001b[39m, in \u001b[36m_convert_listlike_datetimes\u001b[39m\u001b[34m(arg, format, name, utc, unit, errors, dayfirst, yearfirst, exact)\u001b[39m\n\u001b[32m    431\u001b[39m \u001b[38;5;66;03m# `format` could be inferred, or user didn't ask for mixed-format parsing.\u001b[39;00m\n\u001b[32m    432\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mformat\u001b[39m != \u001b[33m\"\u001b[39m\u001b[33mmixed\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m433\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_array_strptime_with_fallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mutc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexact\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    435\u001b[39m result, tz_parsed = objects_to_datetime64(\n\u001b[32m    436\u001b[39m     arg,\n\u001b[32m    437\u001b[39m     dayfirst=dayfirst,\n\u001b[32m   (...)\u001b[39m\u001b[32m    441\u001b[39m     allow_object=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    442\u001b[39m )\n\u001b[32m    444\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tz_parsed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    445\u001b[39m     \u001b[38;5;66;03m# We can take a shortcut since the datetime64 numpy array\u001b[39;00m\n\u001b[32m    446\u001b[39m     \u001b[38;5;66;03m# is in UTC\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\aweso\\financial-news-sentiment-analysis\\.venv\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py:467\u001b[39m, in \u001b[36m_array_strptime_with_fallback\u001b[39m\u001b[34m(arg, name, utc, fmt, exact, errors)\u001b[39m\n\u001b[32m    456\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_array_strptime_with_fallback\u001b[39m(\n\u001b[32m    457\u001b[39m     arg,\n\u001b[32m    458\u001b[39m     name,\n\u001b[32m   (...)\u001b[39m\u001b[32m    462\u001b[39m     errors: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m    463\u001b[39m ) -> Index:\n\u001b[32m    464\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    465\u001b[39m \u001b[33;03m    Call array_strptime, with fallback behavior depending on 'errors'.\u001b[39;00m\n\u001b[32m    466\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m467\u001b[39m     result, tz_out = \u001b[43marray_strptime\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfmt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexact\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexact\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mutc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mutc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    468\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m tz_out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    469\u001b[39m         unit = np.datetime_data(result.dtype)[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mstrptime.pyx:501\u001b[39m, in \u001b[36mpandas._libs.tslibs.strptime.array_strptime\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mstrptime.pyx:451\u001b[39m, in \u001b[36mpandas._libs.tslibs.strptime.array_strptime\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mstrptime.pyx:583\u001b[39m, in \u001b[36mpandas._libs.tslibs.strptime._parse_with_format\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mValueError\u001b[39m: time data \"2020-05-22 00:00:00\" doesn't match format \"%Y-%m-%d %H:%M:%S%z\", at position 10. You might want to try:\n    - passing `format` if your strings have a consistent format;\n    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this."
     ]
    }
   ],
   "source": [
    "# Initialize analyzer\n",
    "analyzer = NewsSentimentAnalyzer(news_data, stock_data)\n",
    "\n",
    "# Calculate sentiment scores\n",
    "news_with_sentiment = analyzer.calculate_sentiment()\n",
    "\n",
    "# Display sentiment distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "news_with_sentiment['sentiment_category'].value_counts().plot(kind='bar')\n",
    "plt.title('Distribution of News Sentiment Categories')\n",
    "plt.xlabel('Sentiment Category')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Each Stock\n",
    "\n",
    "For each stock, we'll:\n",
    "1. Generate a sentiment summary\n",
    "2. Analyze correlation between sentiment and returns\n",
    "3. Plot sentiment analysis results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Analyzing AAPL\n",
      "================================================================================\n",
      "Error analyzing AAPL: name 'analyzer' is not defined\n",
      "\n",
      "================================================================================\n",
      "Analyzing AMZN\n",
      "================================================================================\n",
      "Error analyzing AMZN: name 'analyzer' is not defined\n",
      "\n",
      "================================================================================\n",
      "Analyzing GOOG\n",
      "================================================================================\n",
      "Error analyzing GOOG: name 'analyzer' is not defined\n",
      "\n",
      "================================================================================\n",
      "Analyzing META\n",
      "================================================================================\n",
      "Error analyzing META: name 'analyzer' is not defined\n",
      "\n",
      "================================================================================\n",
      "Analyzing MSFT\n",
      "================================================================================\n",
      "Error analyzing MSFT: name 'analyzer' is not defined\n",
      "\n",
      "================================================================================\n",
      "Analyzing NVDA\n",
      "================================================================================\n",
      "Error analyzing NVDA: name 'analyzer' is not defined\n",
      "\n",
      "================================================================================\n",
      "Analyzing TSLA\n",
      "================================================================================\n",
      "Error analyzing TSLA: name 'analyzer' is not defined\n"
     ]
    }
   ],
   "source": [
    "for symbol in symbols:\n",
    "    if symbol not in stock_data:\n",
    "        print(f\"Skipping {symbol} - no stock data available\")\n",
    "        continue\n",
    "        \n",
    "    print(f\"\\n{'='*80}\\nAnalyzing {symbol}\\n{'='*80}\")\n",
    "    \n",
    "    try:\n",
    "        # Get sentiment summary\n",
    "        summary = analyzer.get_sentiment_summary(symbol)\n",
    "        print(\"\\nSentiment Summary:\")\n",
    "        print(f\"Overall Sentiment: {summary['overall_sentiment']:.2f}\")\n",
    "        print(f\"Total Articles: {summary['total_articles']}\")\n",
    "        print(\"\\nSentiment Distribution:\")\n",
    "        print(summary['sentiment_distribution'])\n",
    "        \n",
    "        # Analyze correlation\n",
    "        correlation = analyzer.analyze_correlation(symbol)\n",
    "        print(\"\\nCorrelation Analysis:\")\n",
    "        print(f\"Overall Correlation: {correlation['overall_correlation']:.3f}\")\n",
    "        print(f\"Best Lag: {correlation['best_lag']} days\")\n",
    "        print(f\"Best Lag Correlation: {correlation['best_lag_correlation']:.3f}\")\n",
    "        \n",
    "        # Plot sentiment analysis\n",
    "        analyzer.plot_sentiment_analysis(symbol)\n",
    "        \n",
    "        # Plot time lag correlation\n",
    "        analyzer.plot_time_lag_correlation(symbol)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error analyzing {symbol}: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Stock Analysis\n",
    "\n",
    "Compare sentiment and correlation metrics across all stocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error collecting metrics for AAPL: name 'analyzer' is not defined\n",
      "Error collecting metrics for AMZN: name 'analyzer' is not defined\n",
      "Error collecting metrics for GOOG: name 'analyzer' is not defined\n",
      "Error collecting metrics for META: name 'analyzer' is not defined\n",
      "Error collecting metrics for MSFT: name 'analyzer' is not defined\n",
      "Error collecting metrics for NVDA: name 'analyzer' is not defined\n",
      "Error collecting metrics for TSLA: name 'analyzer' is not defined\n",
      "No metrics collected - check if sentiment analysis completed successfully\n"
     ]
    }
   ],
   "source": [
    "# Collect metrics for all stocks\n",
    "metrics = []\n",
    "for symbol in symbols:\n",
    "    if symbol not in stock_data:\n",
    "        continue\n",
    "        \n",
    "    try:\n",
    "        summary = analyzer.get_sentiment_summary(symbol)\n",
    "        correlation = analyzer.analyze_correlation(symbol)\n",
    "        \n",
    "        metrics.append({\n",
    "            'Symbol': symbol,\n",
    "            'Overall Sentiment': summary['overall_sentiment'],\n",
    "            'Total Articles': summary['total_articles'],\n",
    "            'Positive %': summary['sentiment_distribution']['positive'],\n",
    "            'Neutral %': summary['sentiment_distribution']['neutral'],\n",
    "            'Negative %': summary['sentiment_distribution']['negative'],\n",
    "            'Correlation': correlation['overall_correlation'],\n",
    "            'Best Lag': correlation['best_lag'],\n",
    "            'Best Lag Correlation': correlation['best_lag_correlation']\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"Error collecting metrics for {symbol}: {str(e)}\")\n",
    "\n",
    "if metrics:\n",
    "    metrics_df = pd.DataFrame(metrics)\n",
    "    metrics_df.set_index('Symbol', inplace=True)\n",
    "\n",
    "    # Plot comparison metrics\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "    # Overall sentiment\n",
    "    metrics_df['Overall Sentiment'].plot(kind='bar', ax=axes[0,0])\n",
    "    axes[0,0].set_title('Overall Sentiment by Stock')\n",
    "    axes[0,0].set_ylabel('Sentiment Score')\n",
    "\n",
    "    # News distribution\n",
    "    metrics_df[['Positive %', 'Neutral %', 'Negative %']].plot(kind='bar', ax=axes[0,1])\n",
    "    axes[0,1].set_title('Sentiment Distribution by Stock')\n",
    "    axes[0,1].set_ylabel('Percentage')\n",
    "\n",
    "    # Correlation\n",
    "    metrics_df['Correlation'].plot(kind='bar', ax=axes[1,0])\n",
    "    axes[1,0].set_title('Sentiment-Return Correlation by Stock')\n",
    "    axes[1,0].set_ylabel('Correlation Coefficient')\n",
    "\n",
    "    # Best lag correlation\n",
    "    metrics_df['Best Lag Correlation'].plot(kind='bar', ax=axes[1,1])\n",
    "    axes[1,1].set_title('Best Lag Correlation by Stock')\n",
    "    axes[1,1].set_ylabel('Correlation Coefficient')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Display metrics table\n",
    "    display(metrics_df.round(3))\n",
    "else:\n",
    "    print(\"No metrics collected - check if sentiment analysis completed successfully\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
